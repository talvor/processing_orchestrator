# Processing Orchestrator

The Processing Orchestrator is a CLI tool built using Cobra to automate workflows defined in a YAML configuration. It loads a series of steps, each with commands, inputs, and outputs, and executes them one by one.

## Configuration File

The orchestrator uses a YAML configuration file to define workflows. Each workflow contains multiple steps. Each step defines the following:

- **`name`**: Unique name for the step.
- **`command`**: Command line execution string.
- **`inputs`** *(optional)*: Files or data needed by the step.
- **`outputs`** *(optional)*: Output files generated by the step.
- **`console`** *(optional)*: Configuration for console output (see below).
- **`output`** *(optional)*: Configuration for capturing output to variables (see below).

### Console Output

Steps can optionally configure console output to display stdout and/or stderr. If not configured, output is suppressed by default.

```yaml
console:
  stdout: true  # Display standard output
  stderr: true  # Display standard error
```

### Output Variables

Steps can capture their stdout and/or stderr output to variables that can be used in later steps. This allows you to pass data between steps dynamically.

```yaml
output:
  stdout: variableName  # Store stdout in this variable
  stderr: errorVar      # Store stderr in this variable
```

Variables can be referenced in later steps using `$variableName` syntax in:
- Commands
- Command arguments
- Preconditions
- When conditions

**Example:**

```yaml
steps:
  - name: "Generate Timestamp"
    command: "date +%Y%m%d_%H%M%S"
    output:
      stdout: timestamp
    console:
      stdout: true

  - name: "Create Timestamped File"
    command: "echo 'Created at: $timestamp' > file_$timestamp.txt"
    depends:
      - "Generate Timestamp"
    console:
      stdout: true
```

**Notes:**
- Output capture is independent of console display - you can capture output with or without displaying it
- Variables are automatically trimmed of leading and trailing whitespace
- Variables can be used in any step that depends on (directly or indirectly) the step that created them

### Example Configuration

```yaml
steps:
  - name: "Download Data"
    command: "wget https://example.com/data.csv -O data.csv"
    outputs:
      - "data.csv"
    console:
      stdout: true
      stderr: true

  - name: "Process Data"
    command: "python process.py data.csv processed_data.csv"
    inputs:
      - "data.csv"
    outputs:
      - "processed_data.csv"
    console:
      stdout: true

  - name: "Generate Report"
    command: "Rscript generate_report.R processed_data.csv report.pdf"
    inputs:
      - "processed_data.csv"
    outputs:
      - "report.pdf"
```

## Usage

1. Place your workflow YAML configuration file in a directory.
2. Run the `process` command with the path to your configuration:

```bash
processing_pipeline process path/to/workflow.yaml
```

## Example Workflow

Step 1: Download a dataset.
Step 2: Preprocess and clean the dataset using a Python script.
Step 3: Generate a final report using an R script.

Customize the YAML configuration to suit your particular workflow.

